{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Houston Machine Learning Meet Up\n",
    "### Neilkunal Panchal\n",
    "#### Saturday 12th October 2019\n",
    "### Multi Agent Reinforcement Learning for Glide Hockey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from mlagents.envs.environment import UnityEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mlagents.envs:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 2\n",
      "        Number of Training Brains : 1\n",
      "        Reset Parameters :\n",
      "\t\tscale -> 1.0\n",
      "\t\tgravity -> 9.8100004196167\n",
      "Unity brain name: HockeyBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): [2]\n",
      "        Vector Action descriptions: , \n",
      "Unity brain name: HockeyPlayer\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): [2]\n",
      "        Vector Action descriptions: left, right\n"
     ]
    }
   ],
   "source": [
    "# env = UnityEnvironment(file_name = \"/Users/neil_panchal/Desktop/AirHockey.app\", worker_id=1)\n",
    "env = UnityEnvironment(file_name = 'AirHockey.app', worker_id=13)\n",
    "default_brain = env.brain_names[0]\n",
    "brain = env.brains[default_brain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the environment\n",
    "env_info = env.reset(train_mode=train_mode)[default_brain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          3.38993621,   0.        ,  -0.        ,   0.        ,\n",
       "         -0.        ,   0.        , -20.        ,   1.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          2.70024681,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,  20.        ,   1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_info.vector_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent state looks like: \n",
      "[  0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           3.38993621   0.          -0.           0.\n",
      "  -0.           0.         -20.           1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Examine the state space for the default brain\n",
    "print(\"Agent state looks like: \\n{}\".format(env_info.vector_observations[0]))\n",
    "\n",
    "# Examine the observation space for the default brain\n",
    "for observation in env_info.visual_observations:\n",
    "    print(\"Agent observations look like:\")\n",
    "    if observation.shape[3] == 3:\n",
    "        plt.imshow(observation[0,:,:,:])\n",
    "    else:\n",
    "        plt.imshow(observation[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "continuous\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          3.38993621,   0.        ,  -0.        ,   0.        ,\n",
       "         -0.        ,   0.        , -20.        ,   1.        ],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          2.70024681,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,  20.        ,   1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(env_info.rewards)\n",
    "print(brain.vector_action_space_type)\n",
    "env_info.vector_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward this episode: -0.1280000302940607\n",
      "Total reward this episode: -2.803000209853053\n",
      "Total reward this episode: -0.0800000112503767\n",
      "Total reward this episode: 0.05899999663233757\n",
      "Total reward this episode: -1.5130001185461879\n",
      "Total reward this episode: -0.1350000249221921\n",
      "Total reward this episode: -0.11300001945346594\n",
      "Total reward this episode: 0.026999990455806255\n",
      "Total reward this episode: 0.05399998649954796\n",
      "Total reward this episode: -0.11400002148002386\n",
      "Total reward this episode: -2.280000166967511\n",
      "Total reward this episode: -0.2200000211596489\n",
      "Total reward this episode: -0.11700002755969763\n",
      "Total reward this episode: -2.6900001894682646\n",
      "Total reward this episode: -2.6900001894682646\n",
      "Total reward this episode: -0.1160000255331397\n",
      "Total reward this episode: -0.12100001610815525\n",
      "Total reward this episode: -5.0100003546103835\n",
      "Total reward this episode: -3.0000002114102244\n",
      "Total reward this episode: -0.1040000207722187\n",
      "Total reward this episode: -0.19900003727525473\n",
      "Total reward this episode: -0.10000001266598701\n",
      "Total reward this episode: 0.0169999897480011\n",
      "Total reward this episode: 0.0749999899417162\n",
      "Total reward this episode: -1.6140001276507974\n",
      "Total reward this episode: -0.1080000288784504\n",
      "Total reward this episode: -0.10500002279877663\n",
      "Total reward this episode: -0.1590000344440341\n",
      "Total reward this episode: -0.09300001803785563\n",
      "Total reward this episode: -0.10600002482533455\n",
      "Total reward this episode: -0.09100001398473978\n",
      "Total reward this episode: -0.39400004129856825\n",
      "Total reward this episode: -0.36000002454966307\n",
      "Total reward this episode: -0.12900003232061863\n",
      "Total reward this episode: -0.09700002614408731\n",
      "Total reward this episode: -5.0100003546103835\n",
      "Total reward this episode: -0.24300002865493298\n",
      "Total reward this episode: 0.06299998518079519\n",
      "Total reward this episode: -0.10600002482533455\n",
      "Total reward this episode: -0.11900003161281347\n",
      "Total reward this episode: -0.06100001186132431\n",
      "Total reward this episode: -0.700000056065619\n",
      "Total reward this episode: -0.11500002350658178\n",
      "Total reward this episode: -2.580000181682408\n",
      "Total reward this episode: -0.11900003161281347\n",
      "Total reward this episode: -1.4940001191571355\n",
      "Total reward this episode: -0.6700000464916229\n",
      "Total reward this episode: -0.10900003090500832\n",
      "Total reward this episode: -0.10700002685189247\n",
      "Total reward this episode: -0.10200001671910286\n",
      "Total reward this episode: -0.11000001337379217\n",
      "Total reward this episode: -0.8400000659748912\n",
      "Total reward this episode: -1.3700000885874033\n",
      "Total reward this episode: -0.10300001874566078\n",
      "Total reward this episode: -0.11500002350658178\n",
      "Total reward this episode: 0.06999999936670065\n",
      "Total reward this episode: -0.10000001266598701\n",
      "Total reward this episode: 0.06699999328702688\n",
      "Total reward this episode: -0.1040000207722187\n",
      "Total reward this episode: -0.11300001945346594\n",
      "Total reward this episode: -0.6000000415369868\n",
      "Total reward this episode: -0.11900003161281347\n",
      "Total reward this episode: -1.3100000992417336\n",
      "Total reward this episode: -0.05500001925975084\n",
      "Total reward this episode: -3.740000263787806\n",
      "Total reward this episode: 0.05399998649954796\n",
      "Total reward this episode: 0.021999980323016644\n",
      "Total reward this episode: -0.1160000255331397\n",
      "Total reward this episode: -0.10100001469254494\n",
      "Total reward this episode: -0.1040000207722187\n",
      "Total reward this episode: -0.10900003090500832\n",
      "Total reward this episode: -0.10900003090500832\n",
      "Total reward this episode: -0.09000001195818186\n",
      "Total reward this episode: -0.03200001176446676\n",
      "Total reward this episode: -0.11500002350658178\n",
      "Total reward this episode: -0.10600002482533455\n",
      "Total reward this episode: 0.01299998164176941\n",
      "Total reward this episode: -0.12900003232061863\n",
      "Total reward this episode: -0.10000001266598701\n",
      "Total reward this episode: 0.03999999724328518\n",
      "Total reward this episode: -0.11000001337379217\n",
      "Total reward this episode: -0.3400000296533108\n",
      "Total reward this episode: 0.023999984376132488\n",
      "Total reward this episode: -0.013000012375414371\n",
      "Total reward this episode: -5.0100003546103835\n",
      "Total reward this episode: -5.0100003546103835\n",
      "Total reward this episode: -3.3300002347677946\n",
      "Total reward this episode: -0.12600002624094486\n",
      "Total reward this episode: -0.7900000624358654\n",
      "Total reward this episode: -2.140000157058239\n",
      "Total reward this episode: -0.32000002171844244\n",
      "Total reward this episode: -0.021000009030103683\n",
      "Total reward this episode: -0.10100001469254494\n",
      "Total reward this episode: 0.014999985694885254\n",
      "Total reward this episode: -3.4200002485886216\n",
      "Total reward this episode: -0.009000023826956749\n",
      "Total reward this episode: -0.11700002755969763\n",
      "Total reward this episode: -1.0800000755116343\n",
      "Total reward this episode: -1.3000000910833478\n",
      "Total reward this episode: -5.0100003546103835\n"
     ]
    }
   ],
   "source": [
    "for episode in range(100):\n",
    "    env_info = env.reset(train_mode=train_mode)[default_brain]\n",
    "    done = False\n",
    "    episode_rewards = 0\n",
    "    while not done:\n",
    "        action_size = brain.vector_action_space_size\n",
    "        if brain.vector_action_space_type == 'continuous':\n",
    "            env_info = env.step(np.random.randn(len(env_info.agents), \n",
    "                                                action_size[0]))[default_brain]\n",
    "        else:\n",
    "            action = np.column_stack([np.random.randint(0, action_size[i], size=(len(env_info.agents))) for i in range(len(action_size))])\n",
    "            env_info = env.step(action)[default_brain]\n",
    "        episode_rewards += env_info.rewards[0]\n",
    "        done = env_info.local_done[0]\n",
    "    print(\"Total reward this episode: {}\".format(episode_rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain\n",
    "#reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: [2]\n",
      "States is: [[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          2.95635414  0.\n",
      "  -0.          0.         -3.62460995 -1.29212058  1.01368487  0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          3.07170582  0.\n",
      "   0.          0.          3.62460995 -1.29212058 -1.01368487  0.        ]]\n",
      "(24,)\n",
      "There are 2 agents. Each observes a state with length: (24,)\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          2.95635414  0.\n",
      " -0.          0.         -3.62460995 -1.29212058  1.01368487  0.        ]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "print('States is:', states)\n",
    "state_size = np.shape(states[1])\n",
    "print(state_size)\n",
    "# state_size=8\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_size[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "print((device is  \"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_info = env.reset(train_mode=train_mode)[brain_name] \n",
    "# actions = get_actions(states, addNoise)           \n",
    "# env_info = env.step(actions)[brain_name] \n",
    "# np.shape(env_info.vector_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state size is: 24\n",
      "action size is : 2\n",
      "on init device is: cpu\n",
      "False\n",
      "action size is:  2\n",
      "action size is:  2\n",
      "on init device is: cpu\n",
      "False\n",
      "action size is:  2\n",
      "action size is:  2\n"
     ]
    }
   ],
   "source": [
    "from ddpg_agent import Agents\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "# num_agents=1\n",
    "# agent = Agents(state_size=state_size, action_size=action_size, num_agents=num_agents, random_seed=0)\n",
    "# agent.action_size\n",
    "print('state size is:', state_size[0])\n",
    "print('action size is :', action_size[0])\n",
    "agent_0 = Agents(state_size=state_size[0], action_size=action_size[0], num_agents=1, random_seed=0)\n",
    "agent_1 = Agents(state_size=state_size[0], action_size=action_size[0], num_agents=1, random_seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(states, add_noise):\n",
    "    '''gets actions for each agent and then combines them into one array'''\n",
    "    action_0 = agent_0.act(states, add_noise)    \n",
    "    action_1 = agent_1.act(states, add_noise)   \n",
    "    return np.concatenate((action_0, action_1), axis=0).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "solved = 1\n",
    "consecutiveEpisodes = 10\n",
    "printFrequency = 1\n",
    "addNoise = True\n",
    "\n",
    "def Maddpg(n_episodes=20, max_t=1000, train_mode=True):\n",
    "    \"\"\"Multi-Agent Deep Deterministic Policy Gradient (MADDPG)\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int)      : maximum number of training episodes\n",
    "        max_t (int)           : maximum number of timesteps per episode\n",
    "        train_mode (bool)     : if 'True' set environment to training mode\n",
    "\n",
    "    \"\"\"\n",
    "    scores_window = deque(maxlen=consecutiveEpisodes)\n",
    "    scores_all = []\n",
    "    moving_average = []\n",
    "    best_score = -np.inf\n",
    "    best_episode = 0\n",
    "    already_solved = False    \n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]  \n",
    "        states = np.reshape(env_info.vector_observations, (1,48)) # combine states\n",
    "        agent_0.reset()\n",
    "        agent_1.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "        while True:\n",
    "            actions = get_actions(states, addNoise)           \n",
    "            env_info = env.step(actions)[brain_name] \n",
    "#             print('shape of observations is', np.shape(env_info.vector_observations))\n",
    "#             print('observations are', env_info.vector_observations)\n",
    "#             print('actions', actions)\n",
    "            next_states = np.reshape(env_info.vector_observations, (1, 48)) # combine the agent next states\n",
    "            rewards = env_info.rewards                         # get reward        \n",
    "            done = env_info.local_done                         # see if episode finished\n",
    "            agent_0.step(states, actions, rewards[0], next_states, done, 0) # agent 1 learning\n",
    "            agent_1.step(states, actions, rewards[1], next_states, done, 1) # agent 2 learning\n",
    "            scores += np.max(rewards)                          # update the score for each agent\n",
    "            states = next_states                              \n",
    "            if np.any(done):                                   # exit loop if episode finished\n",
    "                break\n",
    "\n",
    "        ep_best_score = np.max(scores)\n",
    "        scores_window.append(ep_best_score)\n",
    "        scores_all.append(ep_best_score)\n",
    "        moving_average.append(np.mean(scores_window))\n",
    "\n",
    "        # save best score                        \n",
    "        if ep_best_score > best_score:\n",
    "            best_score = ep_best_score\n",
    "            best_episode = i_episode\n",
    "        \n",
    "        # print results\n",
    "        if i_episode % printFrequency == 0:\n",
    "            print('Episodes {:0>4d}-{:0>4d}\\tMax Reward: {:.3f}\\tMoving Average: {:.3f}'.format(\n",
    "                i_episode-printFrequency, i_episode, np.max(scores_all[-printFrequency:]), moving_average[-1]))\n",
    "\n",
    "        # determine if environment is solved and keep best performing models\n",
    "        if moving_average[-1] >= solved:\n",
    "            if not already_solved:\n",
    "                print('<-- Environment solved in {:d} episodes! \\\n",
    "                \\n<-- Moving Average: {:.3f} over past {:d} episodes'.format(\n",
    "                    i_episode-consecutiveEpisodes, moving_average[-1], consecutiveEpisodes))\n",
    "                already_solved = True\n",
    "                # save weights\n",
    "                torch.save(agent_0.actor_local.state_dict(), 'checkpoint_actor_0.pth')\n",
    "                torch.save(agent_0.critic_local.state_dict(), 'checkpoint_critic_0.pth')\n",
    "                torch.save(agent_1.actor_local.state_dict(), 'checkpoint_actor_1.pth')\n",
    "                torch.save(agent_1.critic_local.state_dict(), 'checkpoint_critic_1.pth')\n",
    "            elif ep_best_score >= best_score:\n",
    "                print('<-- Best episode so far!\\\n",
    "                \\nEpisode {:0>4d}\\tMax Reward: {:.3f}\\tMoving Average: {:.3f}'.format(\n",
    "                i_episode, ep_best_score, moving_average[-1]))\n",
    "                # save weights\n",
    "                torch.save(agent_0.actor_local.state_dict(), 'checkpoint_actor_0.pth')\n",
    "                torch.save(agent_0.critic_local.state_dict(), 'checkpoint_critic_0.pth')\n",
    "                torch.save(agent_1.actor_local.state_dict(), 'checkpoint_actor_1.pth')\n",
    "                torch.save(agent_1.critic_local.state_dict(), 'checkpoint_critic_1.pth')\n",
    "            elif (i_episode-best_episode) >= 100:\n",
    "                # stop training if model stops converging\n",
    "                print('<-- Training stopped. Best score not matched or exceeded for 200 episodes')\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "    return scores_all, moving_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neil_panchal/Desktop/ddpg_agent.py:139: UserWarning: Using a target size (torch.Size([128, 2])) that is different to the input size (torch.Size([128, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.mse_loss(Q_expected, Q_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes 0000-0001\tMax Reward: -3.167\tMoving Average: -3.167\n",
      "Episodes 0001-0002\tMax Reward: -0.438\tMoving Average: -1.803\n",
      "Episodes 0002-0003\tMax Reward: -0.739\tMoving Average: -1.448\n",
      "Episodes 0003-0004\tMax Reward: -0.126\tMoving Average: -1.118\n",
      "Episodes 0004-0005\tMax Reward: -0.221\tMoving Average: -0.938\n",
      "Episodes 0005-0006\tMax Reward: -2.567\tMoving Average: -1.210\n",
      "Episodes 0006-0007\tMax Reward: -3.846\tMoving Average: -1.586\n",
      "Episodes 0007-0008\tMax Reward: -1.566\tMoving Average: -1.584\n",
      "Episodes 0008-0009\tMax Reward: -0.406\tMoving Average: -1.453\n",
      "Episodes 0009-0010\tMax Reward: -2.709\tMoving Average: -1.579\n",
      "Episodes 0010-0011\tMax Reward: -3.614\tMoving Average: -1.623\n",
      "Episodes 0011-0012\tMax Reward: -2.342\tMoving Average: -1.814\n",
      "Episodes 0012-0013\tMax Reward: -0.109\tMoving Average: -1.751\n",
      "Episodes 0013-0014\tMax Reward: -0.995\tMoving Average: -1.838\n",
      "Episodes 0014-0015\tMax Reward: -0.079\tMoving Average: -1.823\n",
      "Episodes 0015-0016\tMax Reward: -0.008\tMoving Average: -1.567\n",
      "Episodes 0016-0017\tMax Reward: -1.593\tMoving Average: -1.342\n",
      "Episodes 0017-0018\tMax Reward: -1.833\tMoving Average: -1.369\n",
      "Episodes 0018-0019\tMax Reward: -0.406\tMoving Average: -1.369\n",
      "Episodes 0019-0020\tMax Reward: -0.109\tMoving Average: -1.109\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores, averages = Maddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSEC_EPISODES = 10\n",
    "PRINT_EVERY = 1\n",
    "addNoise = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on init device is: cpu\n",
      "False\n",
      "action size is:  2\n",
      "action size is:  2\n",
      "on init device is: cpu\n",
      "False\n",
      "action size is:  2\n",
      "action size is:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reinitialize the agents (if needed)\n",
    "agent_0 = Agents(state_size[0], action_size[0], num_agents=1, random_seed=0)\n",
    "agent_1 = Agents(state_size[0], action_size[0], num_agents=1, random_seed=0)\n",
    "\n",
    "# load the weights from file\n",
    "agent_0_weights = 'checkpoint_actor_0.pth'\n",
    "agent_1_weights = 'checkpoint_actor_1.pth'\n",
    "agent_0.actor_local.load_state_dict(torch.load(agent_0_weights))\n",
    "agent_1.actor_local.load_state_dict(torch.load(agent_1_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes 0000-0001\tMax Reward: -0.092\tMoving Average: -0.092\n",
      "Episodes 0001-0002\tMax Reward: -5.010\tMoving Average: -2.551\n",
      "Episodes 0002-0003\tMax Reward: -5.010\tMoving Average: -3.371\n"
     ]
    }
   ],
   "source": [
    "def test(n_episodes=10, max_t=1000, train_mode=False):\n",
    "\n",
    "    scores_window = deque(maxlen=consecutiveEpisodes)\n",
    "    scores_all = []\n",
    "    moving_average = []  \n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=train_mode)[brain_name]         # reset the environment\n",
    "        states = np.reshape(env_info.vector_observations, (1,48)) # get states and combine them\n",
    "        scores = np.zeros(num_agents)\n",
    "        while True:\n",
    "            actions = get_actions(states, addNoise)           # choose agent actions and combine them\n",
    "            env_info = env.step(actions)[brain_name]           # send both agents' actions together to the environment\n",
    "            next_states = np.reshape(env_info.vector_observations, (1, 48)) # combine the agent next states\n",
    "            rewards = env_info.rewards                         # get reward\n",
    "            done = env_info.local_done                         # see if episode finished\n",
    "            scores += np.max(rewards)                          # update the score for each agent\n",
    "            states = next_states                               # roll over states to next time step\n",
    "            if np.any(done):                                   # exit loop if episode finished\n",
    "                break\n",
    "\n",
    "        ep_best_score = np.max(scores)\n",
    "        scores_window.append(ep_best_score)\n",
    "        scores_all.append(ep_best_score)\n",
    "        moving_average.append(np.mean(scores_window))\n",
    "\n",
    "        # print results\n",
    "        if i_episode % printFrequency == 0:\n",
    "            print('Episodes {:0>4d}-{:0>4d}\\tMax Reward: {:.3f}\\tMoving Average: {:.3f}'.format(\n",
    "                i_episode-printFrequency, i_episode, np.max(scores_all[-PRINT_EVERY:]), moving_average[-1]))\n",
    "            \n",
    "    return scores_all, moving_average\n",
    "test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
